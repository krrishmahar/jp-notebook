




















import numpy as np
import tensorflow as tf
import keras


from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

housing = fetch_california_housing()

X_train_full, X_test, y_train_full, y_test = train_test_split(
    housing.data, housing.target)

X_train, X_valid, y_train, y_valid = train_test_split(
    X_train_full, y_train_full, test_size=0.3)



# scaling the data
scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_valid = scaler.transform(X_valid)
X_test = scaler.transform(X_test)


model = keras.Sequential([
    keras.layers.InputLayer(shape=(X_train.shape[1:])),
    keras.layers.Dense(100, kernel_initializer="he_normal"),
    keras.layers.LeakyReLU(alpha=0.2),
    keras.layers.Dense(10, kernel_initializer="he_normal"),
    keras.layers.LeakyReLU(alpha=0.2),
    keras.layers.Dense(1)
])


model.compile(loss="mse", optimizer=keras.optimizers.SGD(learning_rate=1e-4))


%%time
history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), verbose=0)


mse_test = model.evaluate(X_test, y_test)
X_new = X_test[:3]
print(mse_test)
y_pred = model.predict(X_new)











np.any(np.isnan(X_train)), np.any(np.isinf(X_train))


model_reg_semu = keras.Sequential([
    keras.layers.InputLayer(shape=(X_train.shape[1:])),
    keras.layers.Dense(100, activation="selu", kernel_initializer="lecun_normal"),
    keras.layers.AlphaDropout(0.1),
    keras.layers.Dense(10, activation="selu", kernel_initializer="lecun_normal"),
    keras.layers.AlphaDropout(0.1),
    keras.layers.Dense(1)
])


model_reg_semu.compile(loss="mse", optimizer=keras.optimizers.Adam(learning_rate=1e-4))


%%time
history_semu = model_reg_semu.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), verbose=0)


mse_selu_test = model_reg_semu.evaluate(X_test, y_test)
X_new = X_test[:3]
print(mse_selu_test)
y_pred_selu = model_reg_semu.predict(X_new)


model_reg_semu.evaluate(X_test, y_test)








tf.__version__, keras.__version__


fashion_mnist = keras.datasets.fashion_mnist
(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()

X_valid, X_train = X_train[:5000] / 255.0, X_train[5000:] / 255.0
y_valid, y_train = y_train[:5000] , y_train[5000:]

class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat",
"Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]

class_names[y_valid[0]]


X_train = X_train.astype("float32")
X_valid = X_valid.astype("float32")
X_test  = X_test.astype("float32")


np.any(np.isnan(X_train)), np.any(np.isinf(X_train))


np.mean(X_train), np.var(X_train), np.std(X_train)


# ⚠️ Step 2: Normalize to mean = 0, std = 1
# You can't use StandardScaler directly on (n, 28, 28).
# Instead, flatten before scaling, then reshape back to 28×28 for CNN:

from sklearn.preprocessing import StandardScaler

# Flatten images
X_train_flat = X_train.reshape(-1, 28*28)
X_valid_flat = X_valid.reshape(-1, 28*28)
X_test_flat  = X_test.reshape(-1, 28*28)

# Standardize
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_flat)
X_valid_scaled = scaler.transform(X_valid_flat)
X_test_scaled  = scaler.transform(X_test_flat)

# Reshape back for CNN input (add channel dimension)
# here channel C=1 or grayscale
X_train_scaled = X_train_scaled.reshape(-1, 28, 28, 1)
X_valid_scaled = X_valid_scaled.reshape(-1, 28, 28, 1)
X_test_scaled  = X_test_scaled.reshape(-1, 28, 28, 1)


np.mean(X_train_scaled), np.var(X_train_scaled), np.std(X_train_scaled)


from tensorflow import keras
    
model_clf_semu = keras.models.Sequential([
    # keras.layers.InputLayer(),
    keras.layers.Conv2D(32, (3, 3), activation="selu", kernel_initializer="lecun_normal", input_shape=(28, 28, 1)),
    # REMOVE AlphaDropout here
    keras.layers.Conv2D(64, (3, 3), activation="selu", kernel_initializer="lecun_normal"),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation="selu", kernel_initializer="lecun_normal"),
    keras.layers.AlphaDropout(0.1),  # ✅ Safe here
    keras.layers.Dense(10, activation="softmax")
])


model_clf_semu.compile(loss="sparse_categorical_crossentropy",
              optimizer=keras.optimizers.Adam(),
              metrics=["accuracy"])


import os
root_logdir = os.path.join(os.curdir, "my_logs")
def get_run_logdir():
    import time
    run_id = time.strftime("run_%Y_%m_%d-%H_%M_%S")
    return os.path.join(root_logdir, run_id)

run_logdir = get_run_logdir()
run_logdir


early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,
    restore_best_weights=True)


tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)


from timeit import default_timer as timer

start_time = timer()
history_selu_cnn = model_clf_semu.fit(X_train_scaled, y_train, epochs=30, validation_data=(X_valid_scaled, y_valid),
                                     verbose=1, callbacks=[early_stopping_cb, tensorboard_cb])
end_time = timer()
total_time = end_time-start_time
print(f'Total Time Taken: {total_time}')


import pandas as pd
import matplotlib.pyplot as plt
pd.DataFrame(history_selu_cnn.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]
plt.show()


!tensorboard --logdir=./my_logs --port=6006






